{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from random import shuffle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# One-hot encode labels\n",
    "def encode_label(label):\n",
    "    return to_categorical(TARGET_LABELS.index(label), num_classes=len(TARGET_LABELS))\n",
    "\n",
    "# Function to extract label from filename\n",
    "def extract_label_from_filename(filename):\n",
    "    parts = filename.split('-')\n",
    "    if len(parts) == 2 and parts[1].endswith('.pdf'):\n",
    "        label = parts[1].replace('.pdf', '')\n",
    "        if label in TARGET_LABELS :\n",
    "            return label \n",
    "    return None\n",
    "\n",
    "# Function to extract images from PDFs\n",
    "def extract_images_from_path(pdf_path):\n",
    "    images = convert_from_path(pdf_path=pdf_path, grayscale=True)\n",
    "    return images  # Assuming one page per PDF\n",
    "\n",
    "# Convert PIL image to numpy array\n",
    "def pil_images_to_numpy(images):\n",
    "    numpy_images = []\n",
    "    for img in images:\n",
    "        # img = img.convert('RGB')\n",
    "        numpy_images.append(np.array(img))\n",
    "    return numpy_images\n",
    "\n",
    "# Preprocess images (grayscale and resize)\n",
    "def preprocess_images(images, size):\n",
    "    processed_images = []\n",
    "    for image in images:\n",
    "        # gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        resized_image = cv2.resize(image, size)\n",
    "        norm_image = resized_image / 255.0\n",
    "        processed_images.append(norm_image)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "# Function to create training data\n",
    "def create_training_data(base_dir, img_size):\n",
    "    training_data = []\n",
    "    for root, _, files in tqdm(os.walk(base_dir)):\n",
    "        for file in files:\n",
    "            \n",
    "            if file.endswith('.pdf'):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                \n",
    "                label = extract_label_from_filename(file)\n",
    "                if label is None:\n",
    "                    continue\n",
    "                print(pdf_path)\n",
    "                images = extract_images_from_path(pdf_path)\n",
    "                numpy_images = pil_images_to_numpy(images)\n",
    "                preprocessed_images = preprocess_images(numpy_images, img_size)\n",
    "                one_hot_label = encode_label(label)\n",
    "                for processed_image in preprocessed_images:\n",
    "                    training_data.append([processed_image,one_hot_label])\n",
    "    shuffle(training_data)\n",
    "    return training_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7746\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "IMG_SIZE = (224, 317)\n",
    "BASE_DIR = r\"D:\\AIL transfer\\Anyer\\2025\\scan now 5\"\n",
    "MODEL_NAME = 'AIL_detect_model.keras'\n",
    "# Define target labels\n",
    "TARGET_LABELS = [\"PK\", \"BA\", \"PDL\", \"SIP\", \"SPJBTL\", \"PRNYT\", \"FOTO\", \"TOKEN\", \"PMHN\", \"KDBOOK\", \"KK\", \"KTPNPWP\" ]\n",
    "\n",
    "# Create training data\n",
    "# training_data = create_training_data(BASE_DIR, IMG_SIZE)\n",
    "# training_data.extend(create_training_data(BASE_DIR, IMG_SIZE))\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"datajan2025.pkl\", \"wb\") as file:\n",
    "    pickle.dump(training_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatajan2025.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     training_data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"datajan2025.pkl\", \"rb\") as file:\n",
    "    training_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "194/194 [==============================] - 388s 2s/step - loss: 0.5713 - accuracy: 0.8570 - val_loss: 0.1436 - val_accuracy: 0.9639\n",
      "Epoch 2/20\n",
      "194/194 [==============================] - 380s 2s/step - loss: 0.0924 - accuracy: 0.9774 - val_loss: 0.0987 - val_accuracy: 0.9755\n",
      "Epoch 3/20\n",
      "194/194 [==============================] - 279s 1s/step - loss: 0.0602 - accuracy: 0.9839 - val_loss: 0.1071 - val_accuracy: 0.9774\n",
      "Epoch 4/20\n",
      "194/194 [==============================] - 276s 1s/step - loss: 0.0477 - accuracy: 0.9874 - val_loss: 0.0943 - val_accuracy: 0.9800\n",
      "Epoch 5/20\n",
      "194/194 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9903\n",
      "ðŸš¨ Early stopping at epoch 5: val_accuracy = 0.9890, val_loss = 0.0761\n",
      "194/194 [==============================] - 277s 1s/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.0761 - val_accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Custom callback\n",
    "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, acc_threshold=0.98, loss_threshold=0.08):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.acc_threshold = acc_threshold\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc = logs.get(\"val_accuracy\")\n",
    "        loss = logs.get(\"val_loss\")\n",
    "        if acc is not None and loss is not None:\n",
    "            if acc >= self.acc_threshold and loss <= self.loss_threshold:\n",
    "                print(f\"\\nðŸš¨ Early stopping at epoch {epoch + 1}: val_accuracy = {acc:.4f}, val_loss = {loss:.4f}\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "\n",
    "\n",
    "# # Separate features (X) and labels (Y)\n",
    "X = np.array([item[0] for item in training_data]).reshape(-1, IMG_SIZE[1], IMG_SIZE[0], 1)\n",
    "Y = np.array([item[1] for item in training_data])\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[1], IMG_SIZE[0], 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(TARGET_LABELS), activation='softmax')  # Number of classes = length of TARGET_LABELS\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, validation_split= 0.2, batch_size=32, callbacks=[CustomEarlyStopping()] )\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X, Y, epochs=5, validation_split=0.1, batch_size=32)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate features (X) and labels (Y)\n",
    "X = np.array([item[0] for item in training_data]).reshape(-1, IMG_SIZE[1], IMG_SIZE[0], 1)\n",
    "Y = np.array([item[1] for item in training_data])\n",
    "\n",
    "# Define the CNN model\n",
    "model = load_model(MODEL_NAME)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=5, validation_split= 0.2, batch_size=32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
